---
title: Solutions to CS229 Fall 2018 Problem Set 0
subtitle: Linear Algebra and Multivariable Calculus
layout: post
mathjax: true
author: Meyer
catalog: true
header-img: "img/post-bg-miui6.jpg"
tags: 
    - CS229
    - Machine Learning

---

The problem set can be found at [here](https://github.com/Meyer99/Stanford-CS229-Materials/blob/master/problem%20sets/problem%20set%200.pdf). The calculation involved is by default using denominator layout.


### ***1. Gradients and Hessians***  

**Solution:**  
*(a)*  

$$
\nabla f(x) = Ax + b
$$  

Note that $A$ is a symmetric matrix and thus $A = A^T$.

*(b)*  
According to the chain rule, 

$$
\nabla f(x) = \nabla g(h(x)) = \frac{\text{d}g(h)}{\text{d}h} \cdot \nabla h(x)
$$

*(c)*  
From *(a)*, we know $\nabla f(x) = Ax + b$, and hence

$$
\nabla^2f(x)=\frac{\partial}{\partial x}(Ax+b)=A^T=A
$$  

using the identity $\frac{\partial Ax}{\partial x}=A^T$.

*(d)*  
According to the chain rule, 

$$
\nabla f(x) = g'(a^Tx)\cdot \frac{\partial (a^Tx)}{\partial x}=g'(a^Tx)\cdot a
$$

Using the identity 

$$
\frac{\partial vu}{\partial x}=v\frac{\partial u}{\partial x}+\frac{\partial v}{\partial x}u^T
$$

where $v=v(x)$ is a function mapping from vector to scalar and $u=u(x)$ is a function mapping from vector to vector, we have 

$$
\nabla^2 f(x)=\frac{\partial g'(a^Tx)}{\partial x}\cdot a^T=g''(a^Tx)\cdot aa^T
$$

### ***2. Positive definite matrices***  

**Solution:**  
*(a)*  
$\forall x\in \mathbb{R}^n$, $x^TAx=x^Tzz^Tx=(z^Tx)^T(z^Tx)\geq 0$.  
Therefore, $A=zz^T$ is positive semidefinite.

*(b)*

$$
A=zz^T=
\begin{bmatrix}
z_1\\z_2\\\vdots\\z_n
\end{bmatrix}
\begin{bmatrix}
z_1&z_2&\cdots&z_n
\end{bmatrix}
=
\begin{bmatrix}
z_1z_1&z_1z_2&\cdots&z_1z_n\\
z_2z_1&z_2z_2&\cdots&z_2z_n\\  
\cdots&\cdots&\ddots&\cdots\\
z_nz_1&z_nz_2&\cdots&z_nz_n  
\end{bmatrix}
$$

Since $z$ is non-zero, we assume that $z_1\neq 0$ for brevity. For $i=2,3,...,n$, let $r_i-r_1\times \frac{z_i}{z_1}$, $A$ is equivalent to 

$$
\begin{bmatrix}
z_1z_1&z_1z_2&\cdots&z_1z_n\\
0&0&\cdots&0\\  
\cdots&\cdots&\ddots&\cdots\\
0&0&\cdots&0\\  
\end{bmatrix},
$$

and hence its corresponding homogeneous system is 

$$
z_1x_1 + z_2x_2+...+z_nx_n=0
$$

and $\text{rank}(A)=1$.   
Let $x_2, x_3, ..., x_n$ be free variables and 

$$
\begin{bmatrix}x_2\\x_3\\\vdots\\x_n\end{bmatrix}=
\begin{bmatrix}1\\0\\\vdots\\0\end{bmatrix},
\begin{bmatrix}0\\1\\\vdots\\0\end{bmatrix},...,
\begin{bmatrix}0\\0\\\vdots\\1\end{bmatrix}
$$

respectively, plugging into the original system of equations yields 

$$
N(A)=c_2\begin{bmatrix}-z_2/z_1\\1\\0\\\vdots\\0\end{bmatrix} + 
c_3\begin{bmatrix}-z_3/z_1\\0\\1\\\vdots\\0\end{bmatrix} + ... +
c_n\begin{bmatrix}-z_n/z_1\\0\\0\\\vdots\\1\end{bmatrix}
$$

where $c_2, c_3, ..., c_n$ are constants.

*(c)*  
Obviously, $BAB^T$ is symmetric.  
$\forall x\in \mathbb{R}^m$, $x^TBAB^Tx=(B^Tx)^TA(B^Tx)\geq 0$ since $A$ is PSD. Therefore, $BAB^T$ is PSD.

### ***3. Eigenvectors, eigenvalues, and the spectral theorem***  

**Solution:**  
*(a)*  

$$
A=T\Lambda T^{-1}
\Leftrightarrow AT = \Lambda T\\
\Leftrightarrow A\begin{bmatrix}t^{(1)}&t^{(2)}&\cdots&t^{(n)}\end{bmatrix} = \begin{bmatrix}t^{(1)}&t^{(2)}&\cdots&t^{(n)}\end{bmatrix}\Lambda\\
\begin{bmatrix}At^{(1)}&At^{(2)}&\cdots&At^{(n)}\end{bmatrix} = 
\begin{bmatrix}\lambda_1 t^{(1)}&\lambda_2 t^{(2)}&\cdots&\lambda_n t^{(n)}\end{bmatrix}
$$

Hence, $At^{(i)}=\lambda_i t^{(i)}$.

*(b)*  
Given that $U$ is orthogonal and $A=U\Lambda U^T$, so $AU=U\Lambda$. Following the same logic in *(a)*, we have $Au^{(i)}=\lambda_i u^{(i)}$.

*(c)*  
For an eigenvalue $\lambda_i$ of $A$ and its corresponding eigenvector $v_i$, we have $v_i^TAv_i=\lambda_i v_i^Tv_i\geq 0$ since $A$ is PSD and $Av_i=\lambda_iv_i$. 
Since $v_i^Tv_i\geq 0$, it follows that $\lambda_i\geq 0$.
